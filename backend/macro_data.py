import yfinance as yf
import pandas as pd
import os
from datetime import datetime

SP500_CSV_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'sp500.csv')
BTC_CSV_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'frontend', 'public', 'data', 'btc.csv')

def get_sp500_data():
    sp500 = None
    if os.path.exists(SP500_CSV_PATH):
        sp500 = pd.read_csv(SP500_CSV_PATH, index_col=0, parse_dates=True)
        # Ensure index is datetime for comparison
        sp500.index = pd.to_datetime(sp500.index)
        last_date = sp500.index.max()
        # Fetch new data from the day after the last recorded date
        start_date = last_date + pd.Timedelta(days=1)
        today = datetime.now().date()

        if start_date.date() <= today:
            print(f"Fetching new S&P 500 data from {start_date.strftime('%Y-%m-%d')} to today...")
            new_data = yf.Ticker("^GSPC").history(start=start_date, end=today)
            if not new_data.empty:
                # Ensure new_data index is also datetime for concatenation
                new_data.index = pd.to_datetime(new_data.index.date)
                sp500 = pd.concat([sp500, new_data])
                sp500 = sp500[~sp500.index.duplicated(keep='last')] # Remove duplicates if any
                sp500.to_csv(SP500_CSV_PATH)
                print("New S&P 500 data appended and saved.")
            else:
                print("No new S&P 500 data available to fetch.")
        else:
            print("S&P 500 data is already up to date.")
    else:
        print("S&P 500 CSV not found. Fetching full history...")
        sp500 = yf.Ticker("^GSPC").history(period="max")
        sp500.index = pd.to_datetime(sp500.index.date)
        sp500.to_csv(SP500_CSV_PATH)
        print("Full S&P 500 history fetched and saved.")

    # Clean up columns and convert to lower case
    sp500.columns = [c.lower() for c in sp500.columns]
    if "dividends" in sp500.columns: del sp500["dividends"]
    if "stock splits" in sp500.columns: del sp500["stock splits"]

    # Return only relevant columns for charting
    return sp500[["close"]].reset_index().rename(columns={'index': 'date'}).to_dict(orient='records')

def get_sp500_crypto_correlation():
    try:
        # Load S&P 500 data
        if not os.path.exists(SP500_CSV_PATH):
            # Ensure S&P 500 data is fetched if not present
            get_sp500_data() 
        sp500_df = pd.read_csv(SP500_CSV_PATH, index_col=0, parse_dates=True)
        sp500_df.index = pd.to_datetime(sp500_df.index.date)
        sp500_df.columns = [c.lower() for c in sp500_df.columns]

        # Load Bitcoin data
        if not os.path.exists(BTC_CSV_PATH):
            # This part assumes btc.csv is generated by prediction_model.py
            # For standalone use, you might need to fetch it here
            return {"error": "Bitcoin historical data (btc.csv) not found. Run prediction model first.", "details": "btc.csv missing"}
        btc_df = pd.read_csv(BTC_CSV_PATH, index_col=0, parse_dates=True)
        btc_df.index = pd.to_datetime(btc_df.index.date)
        btc_df.columns = [c.lower() for c in btc_df.columns]

        # Merge dataframes on date
        merged_df = pd.merge(btc_df[['close']], sp500_df[['close']], left_index=True, right_index=True, suffixes=('_btc', '_sp500'))
        merged_df = merged_df.dropna()

        if merged_df.empty or len(merged_df) < 2:
            return {"error": "Insufficient data for correlation analysis.", "details": "Merged dataframe is too small."}

        # Calculate daily returns
        merged_df['returns_btc'] = merged_df['close_btc'].pct_change()
        merged_df['returns_sp500'] = merged_df['close_sp500'].pct_change()
        merged_df = merged_df.dropna()

        if merged_df.empty:
            return {"error": "Insufficient data after calculating returns.", "details": "No common return data."}

        # Calculate correlation over different periods
        correlation_30d = merged_df['returns_btc'].tail(30).corr(merged_df['returns_sp500'].tail(30))
        correlation_90d = merged_df['returns_btc'].tail(90).corr(merged_df['returns_sp500'].tail(90))

        # Calculate recent performance changes
        latest_btc_close = merged_df['close_btc'].iloc[-1]
        latest_sp500_close = merged_df['close_sp500'].iloc[-1]

        btc_change_1d = merged_df['close_btc'].pct_change().iloc[-1] * 100
        sp500_change_1d = merged_df['close_sp500'].pct_change().iloc[-1] * 100

        btc_change_7d = (merged_df['close_btc'].iloc[-1] / merged_df['close_btc'].iloc[-7] - 1) * 100 if len(merged_df) >= 7 else None
        sp500_change_7d = (merged_df['close_sp500'].iloc[-1] / merged_df['close_sp500'].iloc[-7] - 1) * 100 if len(merged_df) >= 7 else None

        btc_change_30d = (merged_df['close_btc'].iloc[-1] / merged_df['close_btc'].iloc[-30] - 1) * 100 if len(merged_df) >= 30 else None
        sp500_change_30d = (merged_df['close_sp500'].iloc[-1] / merged_df['close_sp500'].iloc[-30] - 1) * 100 if len(merged_df) >= 30 else None

        return {
            "correlation_30d": correlation_30d if not pd.isna(correlation_30d) else None,
            "correlation_90d": correlation_90d if not pd.isna(correlation_90d) else None,
            "btc_change_1d": btc_change_1d if not pd.isna(btc_change_1d) else None,
            "sp500_change_1d": sp500_change_1d if not pd.isna(sp500_change_1d) else None,
            "btc_change_7d": btc_change_7d if btc_change_7d is not None and not pd.isna(btc_change_7d) else None,
            "sp500_change_7d": sp500_change_7d if sp500_change_7d is not None and not pd.isna(sp500_change_7d) else None,
            "btc_change_30d": btc_change_30d if btc_change_30d is not None and not pd.isna(btc_change_30d) else None,
            "sp500_change_30d": sp500_change_30d if sp500_change_30d is not None and not pd.isna(sp500_change_30d) else None,
            "latest_btc_close": latest_btc_close,
            "latest_sp500_close": latest_sp500_close,
            "recent_data": merged_df[['close_btc', 'close_sp500']].tail(90).reset_index().rename(columns={'index': 'date'}).to_dict(orient='records')
        }
    except Exception as e:
        print(f"Error in get_sp500_crypto_correlation: {e}", file=sys.stderr)
        return {"error": "Failed to perform S&P 500 crypto correlation analysis", "details": str(e)}